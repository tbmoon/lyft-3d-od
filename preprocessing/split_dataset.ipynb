{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from lyft_dataset_sdk.lyftdataset import LyftDataset\n",
    "from lyft_dataset_sdk.utils.data_classes import LidarPointCloud, Box, Quaternion\n",
    "from lyft_dataset_sdk.utils.geometry_utils import view_points, transform_matrix\n",
    "\n",
    "sys.path.insert(0, '/home/mtb/ongoing_analysis/lyft-3d-od')\n",
    "from config import config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = cfg.input_dir\n",
    "output_dir = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyft_dataset = LyftDataset(data_path=os.path.join(input_dir, 'train'), json_path=os.path.join(input_dir, 'train', 'data'), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_records = [(lyft_dataset.get('sample', scene['first_sample_token'])['timestamp'], scene) for scene in lyft_dataset.scene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_entries = []\n",
    "\n",
    "for start_time, scene in sorted(scene_records):\n",
    "    # ex) token: 473093b48a7cb78d05e36245fd2dbd12d66ded7dab1ecb862945390b8a765c0a\n",
    "    #     name: host-a007-lidar0-1230485630199365106-1230485655099030186\n",
    "    #     date: date: 2019-01-02 17:33:50.301987\n",
    "    #     host: host-a007\n",
    "    #     first_sample_token: c7f7de87ec90c8993d4e7d5463208d2aa9f5ecde671960536f39b9a86f939d3c\n",
    "    start_time = lyft_dataset.get('sample', scene['first_sample_token'])['timestamp'] / 1e+6\n",
    "    token = scene['token']\n",
    "    name = scene['name']\n",
    "    date = datetime.utcfromtimestamp(start_time)\n",
    "    host = '-'.join(name.split('-')[:2])\n",
    "    first_sample_token = scene['first_sample_token']\n",
    "    scene_entries.append((host, name, date, token, first_sample_token))\n",
    "    \n",
    "df_scene = pd.DataFrame(scene_entries, columns=['host', 'scene_name', 'date', 'scene_token', 'first_sample_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_host_count = df_scene.groupby('host')['scene_token'].count()\n",
    "df_host_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split the data by car to get a validation set.\n",
    "# Alternatively, we could consider doing it by scenes, date or completely randomly.\n",
    "validation_hosts = ['host-a007', 'host-a008', 'host-a009']\n",
    "df_scene_valid = df_scene[df_scene['host'].isin(validation_hosts)]\n",
    "vi = df_scene_valid.index\n",
    "df_scene_train = df_scene[~df_scene.index.isin(vi)]\n",
    "\n",
    "print(len(df_scene_train), len(df_scene_valid), \"train/validation split scene counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scene_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data_for_scene(entries, scene_token, first_sample_token):\n",
    "    \"\"\"\n",
    "    Given a first sample token (in a scene), output rasterized input volumes and targets in voxel unit perspective.\n",
    "    \"\"\"\n",
    "    sample_token = first_sample_token\n",
    "    while sample_token:\n",
    "        sample = lyft_dataset.get('sample', sample_token)\n",
    "        sample_lidar_token = sample['data']['LIDAR_TOP']\n",
    "        lidar_data = lyft_dataset.get('sample_data', sample_lidar_token)\n",
    "        lidar_filepath = lyft_dataset.get_sample_data_path(sample_lidar_token)\n",
    "\n",
    "        try:\n",
    "            lidar_pointcloud = LidarPointCloud.from_file(lidar_filepath)\n",
    "        except Exception as e:\n",
    "            print('Failed to load Lidar Pointcloud for {}: {}:'.format(sample_token, e))\n",
    "            sample_token = sample['next']\n",
    "            continue\n",
    "        entries.append((scene_token, sample_token))\n",
    "\n",
    "        sample_token = sample['next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df_scene in enumerate ([df_scene_train, df_scene_valid]):\n",
    "    entries = []\n",
    "    scene_tokens = df_scene.scene_token.values\n",
    "    first_sample_tokens = df_scene.first_sample_token.values\n",
    "    \n",
    "    for j in range(len(scene_tokens)):\n",
    "        prepare_training_data_for_scene(entries, scene_tokens[j], first_sample_tokens[j])\n",
    "\n",
    "    if i == 0:\n",
    "        df_sample_train = pd.DataFrame(entries, columns=['scene_token', 'sample_token'])\n",
    "        df_sample_train.to_csv(os.path.join(output_dir, 'train.cvs'))\n",
    "    elif i == 1:\n",
    "        df_sample_valid = pd.DataFrame(entries, columns=['scene_token', 'sample_token'])\n",
    "        df_sample_valid.to_csv(os.path.join(output_dir, 'valid.cvs'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_valid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
