{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import torch\n",
    "import torch.nn\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "from lyft_dataset_sdk.lyftdataset import LyftDataset\n",
    "from lyft_dataset_sdk.utils.data_classes import LidarPointCloud, Box, Quaternion\n",
    "from lyft_dataset_sdk.utils.geometry_utils import view_points, transform_matrix\n",
    "\n",
    "from utils import utils\n",
    "from config import config as cfg\n",
    "from data_loader import get_dataloader\n",
    "from models import VoxelNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_threshold = 0.99\n",
    "pretrained_model = 'model-new-iou.ckpt'\n",
    "sample_token = '7eb3e546df5311b035f1d4b7e88351ffdd85f311ef1bdd22f71a160e92386fed'\n",
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaders, data_sizes = get_dataloader(phases=['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VoxelNet().to(device)\n",
    "checkpoint = torch.load(os.path.join(cfg.work_dir, 'data/models/pretrain', pretrained_model))\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (voxel_features, voxel_coords) in enumerate(data_loaders['test']):\n",
    "    voxel_features = voxel_features.to(device)\n",
    "    voxel_coords = voxel_coords.to(device)\n",
    "    \n",
    "    # psm: [batch_size, R_z, H_map, W_map]\n",
    "    # rm: [batch_size, R_z * B_encode, H_map, W_map]\n",
    "    psm, rm = model(voxel_features, voxel_coords, device)\n",
    "    batch_size = psm.size(0)\n",
    "\n",
    "    # psm: [batch_size, H_map, W_map, R_z]\n",
    "    psm = torch.sigmoid(psm.permute(0,2,3,1))\n",
    "\n",
    "    # psm: [batch_size, H_map * W_map * R_z]\n",
    "    psm = psm.reshape((cfg.batch_size, -1))\n",
    "\n",
    "    # rm: [batch_size, H_map, W_map, R_z * B_encode]\n",
    "    rm = rm.permute(0,2,3,1).contiguous()\n",
    "\n",
    "    # rm: [batch_size, H_map, W_map, R_z, R_z * B_encode]\n",
    "    rm = rm.view(rm.size(0), rm.size(1), rm.size(2), 14)\n",
    "\n",
    "    # prob: [batch_size, H_map * W_map * R_z]\n",
    "    prob = psm.view(batch_size, -1)\n",
    "    \n",
    "    # batch_boxes3d: [batch_size, H_map * W_map * R_z, B_encode]\n",
    "    batch_boxes3d = utils.delta_to_boxes3d(rm, device)\n",
    "\n",
    "    mask = torch.gt(prob, score_threshold)\n",
    "\n",
    "    mask_reg = mask.unsqueeze(2).repeat(1, 1, 7)\n",
    "\n",
    "    batch_id = 0\n",
    "\n",
    "    # boxes3d: [H_map * W_map * R_z, B_encode]\n",
    "    boxes3d = torch.masked_select(batch_boxes3d[batch_id], mask_reg[batch_id]).view(-1, 7)\n",
    "    scores = torch.masked_select(prob[batch_id], mask[batch_id])\n",
    "\n",
    "    # boxes2d_corners: [H_map * W_map * R_z, 4 corners, 2 xy]\n",
    "    boxes3d = boxes3d.cpu().detach().numpy()\n",
    "    boxes2d_corners = utils.boxes3d_to_corners(boxes3d)\n",
    "\n",
    "    print(\"Predicted 2-D Anchor Boxes:\", boxes2d_corners.shape)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(40, 40))\n",
    "\n",
    "ax.plot(boxes2d_corners[:, :, 0].astype(np.float32), boxes2d_corners[:, :, 1].astype(np.float32),\n",
    "        'o', markersize=10)\n",
    "\n",
    "ax.set_xlim([-80, 80])\n",
    "ax.set_ylim([-80, 80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyft_dataset = data_loaders['test'].dataset.lyft_dataset\n",
    "sample = lyft_dataset.get('sample', sample_token)\n",
    "lidar_info = lyft_dataset.get('sample_data', sample['data']['LIDAR_TOP'])\n",
    "lidar_data_path = lyft_dataset.get_sample_data_path(sample['data']['LIDAR_TOP'])\n",
    "gt_boxes3d = lyft_dataset.get_boxes(sample['data']['LIDAR_TOP'])\n",
    "\n",
    "ego_pose = lyft_dataset.get('ego_pose', lidar_info['ego_pose_token'])\n",
    "calibrated_sensor = lyft_dataset.get('calibrated_sensor', lidar_info['calibrated_sensor_token'])\n",
    "\n",
    "pointclouds = LidarPointCloud.from_file(lidar_data_path)\n",
    "pointclouds = pointclouds.points.transpose(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(40, 40))\n",
    "\n",
    "ax.plot(pointclouds[:, 0], pointclouds[:, 1], 'o')\n",
    "ax.plot(boxes2d_corners[:, :, 0].astype(np.float32), boxes2d_corners[:, :, 1].astype(np.float32),\n",
    "        'o', markersize=10)\n",
    "\n",
    "ax.set_xlim([-80, 80])\n",
    "ax.set_ylim([-80, 80])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
